import requests
import os
from .discussions_service import discussion_service
from .history_service import history_service
from .context_service import context_service

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://host.docker.internal:11434")


class GenerateService:
    def __init__(self):
        self.url = f"{OLLAMA_URL}/api/generate"

    def format_messages(self, history):
        """Transforme l'historique des messages pour l'intÃ©grer au prompt"""
        formatted_messages = []
        for msg in history:
            if "question" in msg and "response" in msg:
                formatted_messages.append(f"Utilisateur: {msg['question']}")
                formatted_messages.append(f"Assistant: {msg['response']}")

        return "\n".join(formatted_messages) if formatted_messages else "Aucun historique disponible."

    def generate_response(self, discussion_id: str, question: str, context_id: str):
        """GÃ©nÃ¨re une rÃ©ponse en utilisant le rÃ©sumÃ© et l'historique"""

        # ğŸ”¹ VÃ©rifier si l'ID de discussion est valide
        if not isinstance(discussion_id, str) or len(discussion_id) != 24:
            return {"error": "L'ID de la discussion est invalide"}

        # ğŸ”¹ Charger le contexte
        context = context_service.get_context(context_id)
        if not context:
            return {"error": "Contexte non trouvÃ©"}

        # ğŸ”¹ RÃ©cupÃ©rer le rÃ©sumÃ© de la discussion
        summary = discussion_service.get_summary(discussion_id) or "Aucun rÃ©sumÃ© disponible."

        # ğŸ”¹ RÃ©cupÃ©rer l'historique de la discussion
        history = history_service.get_history_by_discussion(discussion_id)
        formatted_messages = self.format_messages(history)

        # ğŸ”¹ Construire le prompt simple
        prompt = (
            f"ğŸ’¡ **RÃ©sumÃ© de la discussion** :\n{summary}\n\n"
            # f"ğŸ“œ **Historique des Ã©changes** :\n{formatted_messages}\n\n"
            f"ğŸ“ **Nouvelle question** :\nUtilisateur : {question}\nAssistant :"
        )

        print('-----------------------------------------------------------')
        print(f'Prompt envoyÃ© Ã  DeepSeek :\n{prompt}')
        print('-----------------------------------------------------------')

        # ğŸ”¹ Envoyer la requÃªte Ã  Ollama
        response = requests.post(
            self.url,
            json={"model": "deepseek-r1:7b", "prompt": prompt, "stream": False}
        )

        if response.status_code != 200:
            return {"error": f"Erreur avec Ollama: {response.text}"}

        data = response.json()
        answer = data.get("response", "")

        # âœ… Ajouter l'ID de discussion dans l'historique
        history_service.add_history(discussion_id, question, answer, context_id)

        # âœ… Mettre Ã  jour le rÃ©sumÃ© avec l'ID de la discussion
        discussion_service.update_summary(discussion_id, question, answer)

        return {"response": answer}


# Singleton
generate_service = GenerateService()
