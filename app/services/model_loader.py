import logging
import spacy
import flair

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OllamaModel:
    def __init__(self, model_name: str, port: int = 11434):
        self.base_url = f"http://host.docker.internal:{port}"
        self.model_name = model_name

try:
    logger.info("üöÄ Chargement des mod√®les NLP...")

    # Chargement des mod√®les une seule fois - utiliser le mod√®le fran√ßais disponible
    try:
        nlp = spacy.load("fr_core_news_sm")
    except OSError:
        logger.warning("Mod√®le fr_core_news_sm non trouv√©, tentative avec fr_core_news_md")
        try:
            nlp = spacy.load("fr_core_news_md")
        except OSError:
            logger.warning("Mod√®le fr_core_news_md non trouv√©, utilisation du mod√®le anglais par d√©faut")
            nlp = spacy.load("en_core_web_sm")
    
    bert_large = "dbmdz/bert-large-cased-finetuned-conll03-english"
    
    # Configuration du mod√®le d'embedding (port 11434 par d√©faut d'Ollama)
    minilm_model = OllamaModel("nomic-embed-text:latest", port=11434)

    logger.info("‚úÖ Mod√®les charg√©s avec succ√®s !")

except Exception as e:
    logger.error(f"‚ùå Erreur lors du chargement des mod√®les : {e}")
    raise RuntimeError("Impossible de charger les mod√®les NLP.")
